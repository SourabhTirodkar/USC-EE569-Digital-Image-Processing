{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sourabh_Project_HW6_acc63.16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDrMU03Z8b0d",
        "colab_type": "code",
        "outputId": "88158ff4-b30c-4699-96dd-790a66871758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from saab import Saab\n",
        "from cwSaab import cwSaab\n",
        "from pixelhop2 import Pixelhop2\n",
        "from cross_entropy import Cross_Entropy\n",
        "from lag import LAG\n",
        "from skimage.util import view_as_windows\n",
        "import skimage.measure\n",
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#taking image dataset\n",
        "(train_data,train_label), (test_data,test_label)= cifar10.load_data()\n",
        "print(train_data.shape,train_label.shape, test_data.shape, test_label.shape)\n",
        "\n",
        "# Preprocessing\n",
        "train_data=( train_data.astype('float') )\n",
        "test_data=( test_data.astype('float') )\n",
        "train_data /= 255.0\n",
        "test_data /= 255.0\n",
        "\n",
        "# Normalizing data\n",
        "# Calculating mean image \n",
        "mean_image = np.mean(train_data, axis=0) \n",
        "# Calculating standard deviation \n",
        "std = np.std(train_data, axis=0)  \n",
        "\n",
        "# Subtracting calculated mean image from datasets\n",
        "train_data -= mean_image\n",
        "test_data -= mean_image\n",
        "\n",
        "# Dividing then every dataset by standard deviation\n",
        "train_data /= std\n",
        "test_data /= std\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(train_data, train_label, test_size=0.8, random_state=0, stratify= train_label)\n",
        "print(X_train.shape)\n",
        "\n",
        "\n",
        "del Y_train\n",
        "del Y_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWf_8Odq8wQh",
        "colab_type": "code",
        "outputId": "afdceab6-8f57-4e0b-cd66-a1a423dfe876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "start=time.time()\n",
        "def Shrink(X, shrinkArg):\n",
        "  win = shrinkArg['win']\n",
        "  stride = shrinkArg['stride']\n",
        "  ch = X.shape[-1]\n",
        "  X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "  X = X.reshape(X.shape[0], X.shape[1], X.shape[2],-1)\n",
        "  return skimage.measure.block_reduce(X, (1,2,2,1), np.max)\n",
        "\n",
        "\n",
        "# example callback function for how to concate features from different hops\n",
        "def Concat(X, concatArg):\n",
        "  return X\n",
        "\n",
        "SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'useDC':True, 'batch':None, 'cw':False}, \n",
        "              {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True},\n",
        "              {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True}]\n",
        "#               {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True}]\n",
        "shrinkArgs = [{'func': Shrink, 'win':5, 'stride': 1}, \n",
        "               {'func': Shrink, 'win':5, 'stride': 1},\n",
        "                {'func': Shrink, 'win':5, 'stride': 1}]\n",
        "#                {'func': Shrink, 'win':3, 'stride': 1}]\n",
        "concatArg = {'func':Concat}\n",
        "\n",
        "\n",
        "print(\" -----> depth=3\")\n",
        "p2 = Pixelhop2(depth=3, TH1=0.0003, TH2=0.00003, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
        "p2.fit(X_train)\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "\n",
        "output1 = p2.transform(train_data[:5000,:,:])\n",
        "output2 = p2.transform(train_data[5000:10000,:,:])\n",
        "output3 = p2.transform(train_data[10000:15000,:,:])\n",
        "output4 = p2.transform(train_data[15000:20000,:,:])\n",
        "output5 = p2.transform(train_data[20000:25000,:,:])\n",
        "output6 = p2.transform(train_data[25000:30000,:,:])\n",
        "output7 = p2.transform(train_data[30000:35000,:,:])\n",
        "output8 = p2.transform(train_data[35000:40000,:,:])\n",
        "output9 = p2.transform(train_data[40000:45000,:,:])\n",
        "output10 = p2.transform(train_data[45000:50000,:,:])\n",
        "\n",
        "output_1= np.concatenate((output1[0], output2[0], output3[0],output4[0], output5[0], output6[0],output7[0], output8[0], output9[0], output10[0]))\n",
        "output_2= np.concatenate((output1[1], output2[1], output3[1],output4[1], output5[1], output6[1],output7[1], output8[1], output9[1], output10[1]))\n",
        "output_3= np.concatenate((output1[2], output2[2], output3[2],output4[2], output5[2], output6[2],output7[2], output8[2], output9[2], output10[2]))\n",
        "#output_4= np.concatenate((output1[3], output2[3], output3[3],output4[3], output5[3], output6[3],output7[3], output8[3], output9[3], output10[3]))\n",
        "\n",
        "\n",
        "print(output_1.shape, output_2.shape, output_3.shape)\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "\n",
        "# Save module 1 all outputs\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name1 = 'Projecthw6_module1_output_1'\n",
        "model_name2 = 'Projecthw6_module1_output_2'\n",
        "model_name3 = 'Projecthw6_module1_output_3'\n",
        "#model_name4 = 'Projecthw6_module1_output_4'\n",
        "\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path1 = os.path.join(save_dir, model_name1)\n",
        "model_path2 = os.path.join(save_dir, model_name2)\n",
        "model_path3 = os.path.join(save_dir, model_name3)\n",
        "#model_path4 = os.path.join(save_dir, model_name4)\n",
        "\n",
        "\n",
        "np.save(model_path1,output_1)\n",
        "np.save(model_path2,output_2)\n",
        "np.save(model_path3,output_3)\n",
        "#np.save(model_path4,output_4)\n",
        "print('Saved trained model at %s ' % model_path1)\n",
        "print('Saved trained model at %s ' % model_path2)\n",
        "print('Saved trained model at %s ' % model_path3)\n",
        "#print('Saved trained model at %s ' % model_path4)\n",
        "\n",
        "\n",
        "end=time.time()\n",
        "print('Time', end-start)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " -----> depth=3\n",
            "pixelhop2 fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------- DONE -------\n",
            "\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "pixelhop2 transform\n",
            "(50000, 14, 14, 57) (50000, 5, 5, 404) (50000, 1, 1, 1316)\n",
            "------- DONE -------\n",
            "\n",
            "Saved trained model at /content/saved_models/Projecthw6_module1_output_1 \n",
            "Saved trained model at /content/saved_models/Projecthw6_module1_output_2 \n",
            "Saved trained model at /content/saved_models/Projecthw6_module1_output_3 \n",
            "Time 420.2208607196808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwhjfNdZ9I2n",
        "colab_type": "code",
        "outputId": "3d5a57d0-ffec-42d3-8ca0-2cb958f776db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#testing data \n",
        "#part 2\n",
        "\n",
        "output_test=p2.transform(test_data)\n",
        "print(output_test[0].shape, output_test[1].shape, output_test[2].shape)\n",
        "print(\"------- DONE -------\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n",
            "(10000, 14, 14, 57) (10000, 5, 5, 404) (10000, 1, 1, 1316)\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWNOeoAe-iAj",
        "colab_type": "code",
        "outputId": "05bfbfe3-ecd3-4270-af97-d18fa7bc1dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_ori_h1_test = output_test[0].reshape((len(output_test[0]), -1))\n",
        "X_ori_h2_test = output_test[1].reshape((len(output_test[1]), -1))\n",
        "X_ori_h3_test = output_test[2].reshape((len(output_test[2]), -1))\n",
        "#X_ori_h4_test = output_test[3].reshape((len(output_test[3]), -1))\n",
        "\n",
        "print(X_ori_h1_test.shape)\n",
        "print(X_ori_h2_test.shape)\n",
        "print(X_ori_h3_test.shape)\n",
        "#print(X_ori_h4_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 11172)\n",
            "(10000, 10100)\n",
            "(10000, 1316)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-__upVn-tr-",
        "colab_type": "code",
        "outputId": "9e66ad47-9648-4fba-c707-e5174cd56c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "start=time.time()\n",
        "print(\"Module 2: HOP 1\")\n",
        "X_ori_h1 = output_1.reshape((len(output_1), -1))\n",
        "ce = Cross_Entropy(num_class=10, num_bin=5)\n",
        "feat_ce_h1 = np.zeros(X_ori_h1.shape[-1])\n",
        "for k in range(X_ori_h1.shape[-1]):\n",
        "  feat_ce_h1[k] = ce.compute(X_ori_h1[:,k].reshape(-1,1), train_label)\n",
        "  #print(\" --> KMeans ce: %s\"%str(feat_ce[k]))\n",
        "print(\" --> KMeans ce: %s\"%str(feat_ce_h1[k]))\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "# Saving model 2 op1\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'pmodule2_feat_ce_h1'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "np.save(model_path,feat_ce_h1)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "end=time.time()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module 2: HOP 1\n",
            " --> KMeans ce: 0.3249477402191003\n",
            "------- DONE -------\n",
            "\n",
            "Saved trained model at /content/saved_models/pmodule2_feat_ce_h1 \n",
            "501.6690580844879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDz7_-vk-6UP",
        "colab_type": "code",
        "outputId": "64584320-0d20-4980-e63c-32d030c1c1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "start=time.time()\n",
        "print(\"Module 2: HOP 2\")\n",
        "X_ori_h2 = output_2.reshape((len(output_2), -1))\n",
        "ce = Cross_Entropy(num_class=10, num_bin=5)\n",
        "feat_ce_h2 = np.zeros(X_ori_h2.shape[-1])\n",
        "for k in range(X_ori_h2.shape[-1]):\n",
        "  feat_ce_h2[k] = ce.compute(X_ori_h2[:,k].reshape(-1,1), train_label)\n",
        "  #print(\" --> KMeans ce: %s\"%str(feat_ce[k]))\n",
        "print(\" --> KMeans ce: %s\"%str(feat_ce_h2[k]))\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "# Saving model 2 op2\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'pmodule2_feat_ce_h2'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "np.save(model_path,feat_ce_h2)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "end=time.time()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module 2: HOP 2\n",
            " --> KMeans ce: 0.28494741450773864\n",
            "------- DONE -------\n",
            "\n",
            "Saved trained model at /content/saved_models/pmodule2_feat_ce_h2 \n",
            "445.79697704315186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH2JEm-p-7cL",
        "colab_type": "code",
        "outputId": "253d938c-227e-4997-ea84-d099270f9666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "start=time.time()\n",
        "print(\"Module 2: HOP 3\")\n",
        "X_ori_h3 = output_3.reshape((len(output_3), -1))\n",
        "ce = Cross_Entropy(num_class=10, num_bin=5)\n",
        "feat_ce_h3 = np.zeros(X_ori_h3.shape[-1])\n",
        "for k in range(X_ori_h3.shape[-1]):\n",
        "  feat_ce_h3[k] = ce.compute(X_ori_h3[:,k].reshape(-1,1), train_label)\n",
        "  #print(\" --> KMeans ce: %s\"%str(feat_ce[k]))\n",
        "print(\" --> KMeans ce: %s\"%str(feat_ce_h3[k]))\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "# Saving model 2 op3\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'pmodule2_feat_ce_h3'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "np.save(model_path,feat_ce_h3)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "end=time.time()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module 2: HOP 3\n",
            " --> KMeans ce: 0.3249477402191002\n",
            "------- DONE -------\n",
            "\n",
            "Saved trained model at /content/saved_models/pmodule2_feat_ce_h3 \n",
            "55.41390037536621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42gOInoW--Xb",
        "colab_type": "code",
        "outputId": "7be4d5d1-35dc-4ed9-d0c1-c19c4e498b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#Taking top 50% from each cross entropy unit\n",
        "X_ori_h1 = output_1.reshape((len(output_1), -1))\n",
        "X_ori_h2 = output_2.reshape((len(output_2), -1))\n",
        "X_ori_h3 = output_3.reshape((len(output_3), -1))\n",
        "#X_ori_h4 = output_4.reshape((len(output_4), -1))\n",
        "\n",
        "\n",
        "\n",
        "a1 = np.argsort(feat_ce_h1, axis=-1, kind= None, order= None)\n",
        "print(\"Shape %s\"%str(a1.shape))\n",
        "b1=int(len(a1)/2)\n",
        "print(b1)\n",
        "a1=a1[0:1000]\n",
        "print(\"New Shape %s\"%str(a1.shape))\n",
        "new_feat_h1=X_ori_h1[:,a1]\n",
        "print(new_feat_h1.shape)\n",
        "\n",
        "\n",
        "a2 = np.argsort(feat_ce_h2, axis=-1, kind= None, order= None)\n",
        "print(\"Shape %s\"%str(a2.shape))\n",
        "b2=int(len(a2)/2)\n",
        "print(b2)\n",
        "a2=a2[0:1000]\n",
        "print(\"New Shape %s\"%str(a2.shape))\n",
        "new_feat_h2=X_ori_h2[:,a2]\n",
        "print(new_feat_h2.shape)\n",
        "\n",
        "\n",
        "a3 = np.argsort(feat_ce_h3, axis=-1, kind= None, order= None)\n",
        "print(\"Shape %s\"%str(a3.shape))\n",
        "b3=int(len(a3)/2)\n",
        "print(b3)\n",
        "a3=a3[0:1000]\n",
        "print(\"New Shape %s\"%str(a3.shape))\n",
        "new_feat_h3=X_ori_h3[:,a3]\n",
        "print(new_feat_h3.shape)\n",
        "\n",
        "\n",
        "\n",
        "#a4 = np.argsort(feat_ce_h4, axis=-1, kind= None, order= None)\n",
        "#print(\"Shape %s\"%str(a4.shape))\n",
        "#b4=int(len(a4)/2)\n",
        "#print(b4)\n",
        "#a4=a4[0:b4]\n",
        "#print(\"New Shape %s\"%str(a4.shape))\n",
        "#new_feat_h4=X_ori_h3[:,a4]\n",
        "\n",
        "# Saving model 2 op1 new\n",
        "model_name = 'pmodule2_feat_ce_h1_top50'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "np.save(model_path,new_feat_h1)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Saving model 2 op2 new\n",
        "model_name = 'pmodule2_feat_ce_h2_top50'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "np.save(model_path,new_feat_h2)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Saving model 2 op3 new\n",
        "model_name = 'pmodule2_feat_ce_h3_top50'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "np.save(model_path,new_feat_h3)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Saving model 2 op4 new\n",
        "#model_name = 'pmodule2_feat_ce_h4_top50'\n",
        "#model_path = os.path.join(save_dir, model_name)\n",
        "#np.save(model_path,new_feat_h4)\n",
        "#print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape (11172,)\n",
            "5586\n",
            "New Shape (1000,)\n",
            "(50000, 1000)\n",
            "Shape (10100,)\n",
            "5050\n",
            "New Shape (1000,)\n",
            "(50000, 1000)\n",
            "Shape (1316,)\n",
            "658\n",
            "New Shape (1000,)\n",
            "(50000, 1000)\n",
            "Saved trained model at /content/saved_models/pmodule2_feat_ce_h1_top50 \n",
            "Saved trained model at /content/saved_models/pmodule2_feat_ce_h2_top50 \n",
            "Saved trained model at /content/saved_models/pmodule2_feat_ce_h3_top50 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQv-1hAD_Fwi",
        "colab_type": "code",
        "outputId": "63b2833d-f468-45c1-a2dc-b5a8b2667570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "new_feat_h1_test=X_ori_h1_test[:,a1]\n",
        "new_feat_h2_test=X_ori_h2_test[:,a2]\n",
        "new_feat_h3_test=X_ori_h3_test[:,a3]\n",
        "#new_feat_h4_test=X_ori_h4_test[:,a4]\n",
        "print(new_feat_h1_test.shape)\n",
        "print(new_feat_h2_test.shape)\n",
        "print(new_feat_h3_test.shape)\n",
        "\n",
        "print('>----Done----')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1000)\n",
            "(10000, 1000)\n",
            "(10000, 1000)\n",
            ">----Done----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUC0M5N9_TIy",
        "colab_type": "code",
        "outputId": "7ebdb829-1a78-41d2-bfa6-efcf119b787e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from llsr import LLSR as myLLSR\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "lag = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=10, learner=myLLSR(onehot=False))  \n",
        "\n",
        "lag.fit(new_feat_h1, train_label)\n",
        "X_train_trans1 = lag.transform(new_feat_h1)\n",
        "print(X_train_trans1.shape)\n",
        "X_train_trans1_test = lag.transform(new_feat_h1_test)\n",
        "print('Done')\n",
        "\n",
        "lag.fit(new_feat_h2, train_label)\n",
        "X_train_trans2 = lag.transform(new_feat_h2)\n",
        "print(X_train_trans2.shape)\n",
        "X_train_trans2_test = lag.transform(new_feat_h2_test)\n",
        "print('Done')\n",
        "\n",
        "lag.fit(new_feat_h3, train_label)\n",
        "X_train_trans3 = lag.transform(new_feat_h3)\n",
        "print(X_train_trans3.shape)\n",
        "X_train_trans3_test = lag.transform(new_feat_h3_test)\n",
        "print('Done')\n",
        "\n",
        "#lag.fit(new_feat_h4, train_label)\n",
        "#X_train_trans4 = lag.transform(new_feat_h4)\n",
        "\n",
        "X_train_trans = np.concatenate((X_train_trans1,X_train_trans2,X_train_trans3), axis=1)\n",
        "print(X_train_trans.shape)\n",
        "\n",
        "\n",
        "# Saving model 2 op3 new\n",
        "model_name = 'pconcat_4lag_train'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "np.save(model_path,X_train_trans)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "#X_train_predprob = lag.predict_proba(X_train_trans)\n",
        "#print(\" --> train acc: %s\"%str(lag.score(X_train_predprob, train_label)))\n",
        "#print(\" --> test acc.: %s\"%str(lag.score(X_test, y_test)))\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "X_test_trans = np.concatenate((X_train_trans1_test,X_train_trans2_test,X_train_trans3_test), axis=1)\n",
        "\n",
        "# Saving model 2 op3 new\n",
        "model_name = 'pconcat_4lag_test'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "np.save(model_path,X_test_trans)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 50)\n",
            "Done\n",
            "(50000, 50)\n",
            "Done\n",
            "(50000, 50)\n",
            "Done\n",
            "(50000, 150)\n",
            "Saved trained model at /content/saved_models/pconcat_4lag_train \n",
            "------- DONE -------\n",
            "\n",
            "Saved trained model at /content/saved_models/pconcat_4lag_test \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leJQv-W-_4RX",
        "colab_type": "code",
        "outputId": "506eaca5-7442-4d91-b925-432c46106990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "start=time.time()\n",
        "\n",
        "clf1 = RandomForestClassifier(n_estimators=500)\n",
        "clf1.fit(X_train_trans,train_label)\n",
        "X_train_pred = clf1.predict(X_train_trans)\n",
        "\n",
        "store=accuracy_score(train_label,X_train_pred)\n",
        "print(\" --> Train acc: \",store)\n",
        "end=time.time()\n",
        "print('Total time', end- start)\n",
        "print(\"------- DONE -------\\n\")\n",
        "\n",
        "\n",
        "# Saving  classifier\n",
        "import os\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model_name = 'classifier1'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "np.save(model_path,clf1)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " --> Train acc:  1.0\n",
            "Total time 561.1627118587494\n",
            "------- DONE -------\n",
            "\n",
            "Saved trained model at /content/saved_models/classifier1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbM5uUWO_7xm",
        "colab_type": "code",
        "outputId": "1bac19db-534c-4e92-abc3-a9fef9e88cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#prediction for test\n",
        "\n",
        "X_test_pred = clf1.predict(X_test_trans)\n",
        "\n",
        "store_test=accuracy_score(test_label,X_test_pred)\n",
        "print(\" --> Testing Accuracy: \",store_test)\n",
        "print(\"------- DONE -------\\n\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " --> Testing Accuracy:  0.6316\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}